{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901da170",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khurs\\projects\\.venv\\Lib\\site-packages\\matplotlib\\style\\core.py:129\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     style = \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khurs\\projects\\.venv\\Lib\\site-packages\\matplotlib\\__init__.py:903\u001b[39m, in \u001b[36m_rc_params_in_file\u001b[39m\u001b[34m(fname, transform, fail_on_error)\u001b[39m\n\u001b[32m    902\u001b[39m rc_temp = {}\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:141\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khurs\\projects\\.venv\\Lib\\site-packages\\matplotlib\\__init__.py:880\u001b[39m, in \u001b[36m_open_file_or_url\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m    879\u001b[39m fname = os.path.expanduser(fname)\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'seaborn-whitegrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Set plot style\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseaborn-whitegrid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m plt.rcParams[\u001b[33m'\u001b[39m\u001b[33mfigure.figsize\u001b[39m\u001b[33m'\u001b[39m] = (\u001b[32m12\u001b[39m, \u001b[32m8\u001b[39m)\n\u001b[32m     28\u001b[39m plt.rcParams[\u001b[33m'\u001b[39m\u001b[33mfont.size\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m12\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\khurs\\projects\\.venv\\Lib\\site-packages\\matplotlib\\style\\core.py:131\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    129\u001b[39m         style = _rc_params_in_file(style)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    132\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m is not a valid package style, path of style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile, URL of style file, or library style name (library \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstyles are listed in `style.available`)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    135\u001b[39m filtered = {}\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: 'seaborn-whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "# Parking Garage Availability Prediction System\n",
    "# Complete Machine Learning Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import pickle\n",
    "import joblib\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# 1. Data Loading and Initial Exploration\n",
    "print(\"Step 1: Loading and exploring the data...\")\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('parking_data_2024.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "print(\"\\nStep 2: Data Preprocessing...\")\n",
    "\n",
    "# Convert 'Time' to datetime format\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "# Extract relevant time features\n",
    "df['Hour'] = df['Time'].dt.hour\n",
    "df['Minute'] = df['Time'].dt.minute\n",
    "df['Day'] = df['Time'].dt.day\n",
    "df['Month'] = df['Time'].dt.month\n",
    "df['Year'] = df['Time'].dt.year\n",
    "df['DayOfWeek'] = df['Time'].dt.dayofweek  # 0 is Monday, 6 is Sunday\n",
    "df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "df['TimeOfDay'] = df['Hour'].apply(lambda x: \n",
    "                                 'Morning' if 5 <= x < 12 else\n",
    "                                 'Afternoon' if 12 <= x < 17 else\n",
    "                                 'Evening' if 17 <= x < 21 else\n",
    "                                 'Night')\n",
    "\n",
    "# Calculate available spots from percentage and capacity\n",
    "df['Available_Spots'] = (df['Free Avg %'] / 100) * df['Capacity']\n",
    "df['Available_Spots'] = df['Available_Spots'].round().astype(int)\n",
    "\n",
    "# 3. Exploratory Data Analysis\n",
    "print(\"\\nStep 3: Exploratory Data Analysis...\")\n",
    "\n",
    "# Create a figure for visualization\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Plot 1: Occupancy by hour of day\n",
    "plt.subplot(2, 2, 1)\n",
    "hourly_occupancy = df.groupby('Hour')['Occ Avg %'].mean()\n",
    "sns.lineplot(x=hourly_occupancy.index, y=hourly_occupancy.values)\n",
    "plt.title('Average Occupancy by Hour of Day')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Occupancy %')\n",
    "\n",
    "# Plot 2: Occupancy by day of week\n",
    "plt.subplot(2, 2, 2)\n",
    "daily_occupancy = df.groupby('DayOfWeek')['Occ Avg %'].mean()\n",
    "sns.barplot(x=daily_occupancy.index, y=daily_occupancy.values)\n",
    "plt.title('Average Occupancy by Day of Week')\n",
    "plt.xlabel('Day of Week (0=Monday, 6=Sunday)')\n",
    "plt.ylabel('Occupancy %')\n",
    "\n",
    "# Plot 3: Occupancy by garage level\n",
    "plt.subplot(2, 2, 3)\n",
    "level_occupancy = df.groupby('Level')['Occ Avg %'].mean().sort_values(ascending=False)\n",
    "sns.barplot(x=level_occupancy.index, y=level_occupancy.values)\n",
    "plt.title('Average Occupancy by Garage Level')\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel('Occupancy %')\n",
    "\n",
    "# Plot 4: Distribution of available spots\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(df['Available_Spots'], kde=True)\n",
    "plt.title('Distribution of Available Parking Spots')\n",
    "plt.xlabel('Number of Available Spots')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional visualizations\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot 5: Heatmap of occupancy by hour and day of week\n",
    "pivot_table = df.pivot_table(values='Occ Avg %', index='Hour', columns='DayOfWeek', aggfunc='mean')\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(pivot_table, cmap='YlGnBu', annot=True, fmt='.1f')\n",
    "plt.title('Occupancy Heatmap by Hour and Day of Week')\n",
    "plt.xlabel('Day of Week (0=Monday, 6=Sunday)')\n",
    "plt.ylabel('Hour of Day')\n",
    "\n",
    "# Plot 6: Time series of occupancy over a few days\n",
    "plt.subplot(1, 2, 2)\n",
    "# Select the first 7 days of data\n",
    "start_date = df['Time'].min()\n",
    "end_date = start_date + pd.Timedelta(days=7)\n",
    "time_slice = df[(df['Time'] >= start_date) & (df['Time'] < end_date)]\n",
    "time_series = time_slice.groupby(time_slice['Time'].dt.date)['Occ Avg %'].mean()\n",
    "sns.lineplot(x=time_series.index, y=time_series.values)\n",
    "plt.title('Occupancy Trend Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Occupancy %')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Feature Engineering\n",
    "print(\"\\nStep 4: Feature Engineering...\")\n",
    "\n",
    "# Create cyclic features for time components\n",
    "df['Hour_sin'] = np.sin(2 * np.pi * df['Hour']/24)\n",
    "df['Hour_cos'] = np.cos(2 * np.pi * df['Hour']/24)\n",
    "df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['DayOfWeek']/7)\n",
    "df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['DayOfWeek']/7)\n",
    "df['Month_sin'] = np.sin(2 * np.pi * df['Month']/12)\n",
    "df['Month_cos'] = np.cos(2 * np.pi * df['Month']/12)\n",
    "\n",
    "# Create lag features (previous hour's occupancy)\n",
    "df['Prev_Hour_Occupancy'] = df.groupby(['Level', 'DayOfWeek'])['Occ Avg %'].shift(1)\n",
    "df['Prev_Hour_Available'] = df.groupby(['Level', 'DayOfWeek'])['Available_Spots'].shift(1)\n",
    "\n",
    "# Create moving averages\n",
    "df['MA_3hours'] = df.groupby(['Level', 'DayOfWeek'])['Occ Avg %'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "df['MA_Day'] = df.groupby(['Level', 'DayOfWeek'])['Occ Avg %'].transform(lambda x: x.rolling(window=48, min_periods=1).mean())  # 48 half-hour intervals per day\n",
    "\n",
    "# Drop rows with NaN values created by lag features\n",
    "df = df.dropna()\n",
    "\n",
    "# 5. Feature Selection and Data Split\n",
    "print(\"\\nStep 5: Feature Selection and Data Split...\")\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['Hour', 'Minute', 'Day', 'Month', 'DayOfWeek', 'IsWeekend',\n",
    "            'Hour_sin', 'Hour_cos', 'DayOfWeek_sin', 'DayOfWeek_cos', 'Month_sin', 'Month_cos',\n",
    "            'Prev_Hour_Occupancy', 'Prev_Hour_Available', 'MA_3hours', 'MA_Day', 'Capacity']\n",
    "\n",
    "# Add one-hot encoded garage level\n",
    "level_dummies = pd.get_dummies(df['Level'], prefix='Level')\n",
    "df = pd.concat([df, level_dummies], axis=1)\n",
    "level_columns = level_dummies.columns.tolist()\n",
    "features.extend(level_columns)\n",
    "\n",
    "# Add one-hot encoded time of day\n",
    "timeofday_dummies = pd.get_dummies(df['TimeOfDay'], prefix='TimeOfDay')\n",
    "df = pd.concat([df, timeofday_dummies], axis=1)\n",
    "timeofday_columns = timeofday_dummies.columns.tolist()\n",
    "features.extend(timeofday_columns)\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df[features]\n",
    "y = df['Available_Spots']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the numerical features\n",
    "numeric_features = ['Hour', 'Minute', 'Day', 'Month', 'DayOfWeek', 'IsWeekend',\n",
    "                   'Hour_sin', 'Hour_cos', 'DayOfWeek_sin', 'DayOfWeek_cos', 'Month_sin', 'Month_cos',\n",
    "                   'Prev_Hour_Occupancy', 'Prev_Hour_Available', 'MA_3hours', 'MA_Day', 'Capacity']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 6. Model Selection and Training\n",
    "print(\"\\nStep 6: Model Selection and Training...\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Create pipeline with preprocessing\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'pipeline': pipeline,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'Predictions': y_pred\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    results[name] = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'MSE': [results[model]['MSE'] for model in results],\n",
    "    'RMSE': [results[model]['RMSE'] for model in results],\n",
    "    'MAE': [results[model]['MAE'] for model in results],\n",
    "    'R2': [results[model]['R2'] for model in results]\n",
    "})\n",
    "display(model_comparison.sort_values('RMSE'))\n",
    "\n",
    "# Find the best model based on RMSE\n",
    "best_model_name = model_comparison.sort_values('RMSE').iloc[0]['Model']\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "\n",
    "# 7. Hyperparameter Tuning for the Best Model\n",
    "print(\"\\nStep 7: Hyperparameter Tuning...\")\n",
    "\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__max_depth': [None, 10, 20, 30],\n",
    "        'model__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'model__max_depth': [3, 5, 7]\n",
    "    }\n",
    "elif best_model_name == 'XGBoost':\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "else:  # Linear Regression\n",
    "    param_grid = {\n",
    "        'model__fit_intercept': [True, False],\n",
    "        'model__normalize': [True, False]\n",
    "    }\n",
    "\n",
    "# Create the pipeline\n",
    "best_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', models[best_model_name])\n",
    "])\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    best_pipeline,\n",
    "    param_grid,\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "best_rmse = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "best_mae = mean_absolute_error(y_test, y_pred_best)\n",
    "best_r2 = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Best Model RMSE: {best_rmse:.2f}\")\n",
    "print(f\"Best Model MAE: {best_mae:.2f}\")\n",
    "print(f\"Best Model R2: {best_r2:.2f}\")\n",
    "\n",
    "# 8. Model Visualization and Analysis\n",
    "print(\"\\nStep 8: Model Visualization and Analysis...\")\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Available Spots')\n",
    "plt.ylabel('Predicted Available Spots')\n",
    "plt.title('Actual vs Predicted Parking Availability')\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "residuals = y_test - y_pred_best\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Available Spots')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importance (if applicable)\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost']:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Extract feature importance\n",
    "    if best_model_name == 'XGBoost':\n",
    "        # Get feature importances from the model\n",
    "        importances = best_model.named_steps['model'].feature_importances_\n",
    "    else:\n",
    "        importances = best_model.named_steps['model'].feature_importances_\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = numeric_features + [col for col in X.columns if col not in numeric_features]\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot top 15 features\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
    "    plt.title(f'Top 15 Feature Importance - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 9. Time Series Validation\n",
    "print(\"\\nStep 9: Time Series Validation...\")\n",
    "\n",
    "# Sort data by time for proper time series validation\n",
    "df_sorted = df.sort_values('Time')\n",
    "X_sorted = df_sorted[features]\n",
    "y_sorted = df_sorted['Available_Spots']\n",
    "\n",
    "# Create TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize lists to store results\n",
    "cv_rmse = []\n",
    "cv_mae = []\n",
    "cv_r2 = []\n",
    "\n",
    "# Perform time series cross validation\n",
    "for train_index, test_index in tscv.split(X_sorted):\n",
    "    X_train_cv, X_test_cv = X_sorted.iloc[train_index], X_sorted.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y_sorted.iloc[train_index], y_sorted.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    best_model.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_cv = best_model.predict(X_test_cv)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cv_rmse.append(np.sqrt(mean_squared_error(y_test_cv, y_pred_cv)))\n",
    "    cv_mae.append(mean_absolute_error(y_test_cv, y_pred_cv))\n",
    "    cv_r2.append(r2_score(y_test_cv, y_pred_cv))\n",
    "\n",
    "# Display time series validation results\n",
    "print(f\"Time Series CV - Mean RMSE: {np.mean(cv_rmse):.2f} (±{np.std(cv_rmse):.2f})\")\n",
    "print(f\"Time Series CV - Mean MAE: {np.mean(cv_mae):.2f} (±{np.std(cv_mae):.2f})\")\n",
    "print(f\"Time Series CV - Mean R2: {np.mean(cv_r2):.2f} (±{np.std(cv_r2):.2f})\")\n",
    "\n",
    "# 10. Forecasting Future Availability\n",
    "print(\"\\nStep 10: Forecasting Future Availability...\")\n",
    "\n",
    "# Function to predict availability for a specific day and garage level\n",
    "def predict_availability(model, date, level, capacity):\n",
    "    # Create a date range for the entire day (30 min intervals)\n",
    "    date_range = pd.date_range(\n",
    "        start=pd.Timestamp(date).replace(hour=0, minute=0), \n",
    "        end=pd.Timestamp(date).replace(hour=23, minute=30),\n",
    "        freq='30min'\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame for prediction\n",
    "    pred_df = pd.DataFrame({'Time': date_range})\n",
    "    \n",
    "    # Extract time features\n",
    "    pred_df['Hour'] = pred_df['Time'].dt.hour\n",
    "    pred_df['Minute'] = pred_df['Time'].dt.minute\n",
    "    pred_df['Day'] = pred_df['Time'].dt.day\n",
    "    pred_df['Month'] = pred_df['Time'].dt.month\n",
    "    pred_df['DayOfWeek'] = pred_df['Time'].dt.dayofweek\n",
    "    pred_df['IsWeekend'] = pred_df['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    pred_df['Hour_sin'] = np.sin(2 * np.pi * pred_df['Hour']/24)\n",
    "    pred_df['Hour_cos'] = np.cos(2 * np.pi * pred_df['Hour']/24)\n",
    "    pred_df['DayOfWeek_sin'] = np.sin(2 * np.pi * pred_df['DayOfWeek']/7)\n",
    "    pred_df['DayOfWeek_cos'] = np.cos(2 * np.pi * pred_df['DayOfWeek']/7)\n",
    "    pred_df['Month_sin'] = np.sin(2 * np.pi * pred_df['Month']/12)\n",
    "    pred_df['Month_cos'] = np.cos(2 * np.pi * pred_df['Month']/12)\n",
    "    \n",
    "    # Set garage level and capacity\n",
    "    pred_df['Level'] = level\n",
    "    pred_df['Capacity'] = capacity\n",
    "    \n",
    "    # Create time of day feature\n",
    "    pred_df['TimeOfDay'] = pred_df['Hour'].apply(lambda x: \n",
    "                                                'Morning' if 5 <= x < 12 else\n",
    "                                                'Afternoon' if 12 <= x < 17 else\n",
    "                                                'Evening' if 17 <= x < 21 else\n",
    "                                                'Night')\n",
    "    \n",
    "    # Create one-hot encodings\n",
    "    level_dummies = pd.get_dummies(pred_df['Level'], prefix='Level')\n",
    "    pred_df = pd.concat([pred_df, level_dummies], axis=1)\n",
    "    \n",
    "    timeofday_dummies = pd.get_dummies(pred_df['TimeOfDay'], prefix='TimeOfDay')\n",
    "    pred_df = pd.concat([pred_df, timeofday_dummies], axis=1)\n",
    "    \n",
    "    # Fill in missing lag values (since we don't have previous data)\n",
    "    # For simplicity, we'll use the median values from our training data\n",
    "    pred_df['Prev_Hour_Occupancy'] = df['Occ Avg %'].median()\n",
    "    pred_df['Prev_Hour_Available'] = df['Available_Spots'].median()\n",
    "    pred_df['MA_3hours'] = df['Occ Avg %'].median()\n",
    "    pred_df['MA_Day'] = df['Occ Avg %'].median()\n",
    "    \n",
    "    # For the second and subsequent predictions, update with previous predictions\n",
    "    for i in range(1, len(pred_df)):\n",
    "        # Update previous hour values based on earlier predictions\n",
    "        if i > 0:\n",
    "            # We need to estimate occupancy from available spots\n",
    "            est_occupancy = 100 - (pred_df.loc[i-1, 'predicted_available'] / capacity * 100)\n",
    "            pred_df.loc[i, 'Prev_Hour_Occupancy'] = est_occupancy\n",
    "            pred_df.loc[i, 'Prev_Hour_Available'] = pred_df.loc[i-1, 'predicted_available']\n",
    "        \n",
    "        # Update moving averages (simplified)\n",
    "        if i >= 3:\n",
    "            occupancy_values = [100 - (pred_df.loc[i-j, 'predicted_available'] / capacity * 100) for j in range(1, 4)]\n",
    "            pred_df.loc[i, 'MA_3hours'] = sum(occupancy_values) / 3\n",
    "    \n",
    "    # Select the features needed for prediction\n",
    "    X_pred = pred_df[features]\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_pred)\n",
    "    pred_df['predicted_available'] = np.round(predictions).astype(int)\n",
    "    \n",
    "    # Ensure predictions are within bounds\n",
    "    pred_df['predicted_available'] = pred_df['predicted_available'].clip(0, capacity)\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "# Example: Predict availability for next day on Level 1\n",
    "today = pd.Timestamp.now().date()\n",
    "tomorrow = today + pd.Timedelta(days=1)\n",
    "sample_level = df['Level'].iloc[0]  # Get a sample level from the data\n",
    "sample_capacity = df[df['Level'] == sample_level]['Capacity'].iloc[0]\n",
    "\n",
    "forecast = predict_availability(best_model, tomorrow, sample_level, sample_capacity)\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(forecast['Time'], forecast['predicted_available'], 'b-', marker='o', alpha=0.6)\n",
    "plt.axhline(sample_capacity, color='r', linestyle='--', label='Total Capacity')\n",
    "plt.fill_between(forecast['Time'], 0, forecast['predicted_available'], alpha=0.3, color='green')\n",
    "plt.title(f'Forecasted Parking Availability for {tomorrow} (Level {sample_level})')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Available Parking Spots')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 11. Model Deployment and Persistence\n",
    "print(\"\\nStep 11: Model Deployment and Persistence...\")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'parking_availability_predictor.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"Model saved as '{model_filename}'\")\n",
    "\n",
    "# Create a simple function for making predictions\n",
    "def predict_parking_availability(date_str, level, model_file='parking_availability_predictor.joblib'):\n",
    "    \"\"\"\n",
    "    Predict parking availability for a given date and garage level.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    date_str : str\n",
    "        Date in format 'YYYY-MM-DD'\n",
    "    level : str\n",
    "        Garage level to predict for\n",
    "    model_file : str\n",
    "        Path to the saved model file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with predictions for each 30-minute interval of the day\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    loaded_model = joblib.load(model_file)\n",
    "    \n",
    "    # Get capacity for the level\n",
    "    level_capacity = df[df['Level'] == level]['Capacity'].iloc[0]\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = predict_availability(loaded_model, date_str, level, level_capacity)\n",
    "    \n",
    "    # Format output for display\n",
    "    results = predictions[['Time', 'predicted_available']].copy()\n",
    "    results['Occupancy_Percentage'] = 100 - (results['predicted_available'] / level_capacity * 100)\n",
    "    results['Time'] = results['Time'].dt.strftime('%H:%M')\n",
    "    results.rename(columns={'predicted_available': 'Available_Spots'}, inplace=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nExample prediction for tomorrow:\")\n",
    "example_prediction = predict_parking_availability(tomorrow.strftime('%Y-%m-%d'), sample_level)\n",
    "display(example_prediction.head(10))  # Show first 10 time slots\n",
    "\n",
    "# 12. Conclusion and Next Steps\n",
    "print(\"\\nStep 12: Conclusion and Next Steps...\")\n",
    "\n",
    "print(\"\"\"\n",
    "Parking Availability Prediction System successfully created!\n",
    "\n",
    "Summary:\n",
    "1. We've loaded and explored the dataset\n",
    "2. Performed feature engineering to extract time-based patterns\n",
    "3. Trained multiple models and selected the best one\n",
    "4. Tuned hyperparameters to optimize performance\n",
    "5. Developed a forecasting system for predicting future availability\n",
    "6. Saved the model for deployment\n",
    "\n",
    "Next Steps:\n",
    "1. Deploy the model as a web service or dashboard\n",
    "2. Set up scheduled retraining as new data becomes available\n",
    "3. Implement real-time data integration\n",
    "4. Add alert systems for when capacity reaches critical thresholds\n",
    "5. Expand to include weather data, event data, and other external factors\n",
    "\n",
    "The model can now be used to predict parking availability for any date and garage level!\n",
    "\"\"\")\n",
    "\n",
    "# Create a simple prediction function for interactive use\n",
    "def interactive_predict():\n",
    "    print(\"Interactive Parking Availability Predictor\")\n",
    "    print(\"------------------------------------------\")\n",
    "    \n",
    "    # Get user inputs\n",
    "    date_input = input(\"Enter date (YYYY-MM-DD) or 'today'/'tomorrow': \")\n",
    "    \n",
    "    if date_input.lower() == 'today':\n",
    "        date = pd.Timestamp.now().date()\n",
    "    elif date_input.lower() == 'tomorrow':\n",
    "        date = pd.Timestamp.now().date() + pd.Timedelta(days=1)\n",
    "    else:\n",
    "        try:\n",
    "            date = pd.to_datetime(date_input).date()\n",
    "        except:\n",
    "            print(\"Invalid date format. Using tomorrow's date.\")\n",
    "            date = pd.Timestamp.now().date() + pd.Timedelta(days=1)\n",
    "    \n",
    "    # Show available levels\n",
    "    unique_levels = df['Level'].unique()\n",
    "    print(f\"Available levels: {', '.join(unique_levels)}\")\n",
    "    \n",
    "    level_input = input(f\"Enter level (default: {unique_levels[0]}): \") or unique_levels[0]\n",
    "    \n",
    "    # Make prediction\n",
    "    try:\n",
    "        predictions = predict_parking_availability(date.strftime('%Y-%m-%d'), level_input)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nPredicted Parking Availability for {date} (Level {level_input}):\")\n",
    "        display(predictions)\n",
    "        \n",
    "        # Create a visualization\n",
    "        level_capacity = df[df['Level'] == level_input]['Capacity'].iloc[0]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(predictions['Time'], predictions['Available_Spots'], 'b-', marker='o', alpha=0.6)\n",
    "        plt.axhline(level_capacity, color='r', linestyle='--', label='Total Capacity')\n",
    "        plt.fill_between(range(len(predictions)), 0, predictions['Available_Spots'], alpha=0.3, color='green')\n",
    "        plt.title(f'Forecasted Parking Availability for {date} (Level {level_input})')\n",
    "        plt.xlabel('Time of Day')\n",
    "        plt.ylabel('Available Parking Spots')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error making prediction: {e}\")\n",
    "\n",
    "print(\"\\nRun the following function to make interactive predictions:\")\n",
    "print(\"interactive_predict()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
